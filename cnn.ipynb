{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "twitter_sentiment_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Ka0vhObbLM"
      },
      "source": [
        "# **CNN Twitter Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLAGzoUhomx8",
        "outputId": "7a27de66-8304-46f0-9066-71a613eeea8a"
      },
      "source": [
        "from google.colab import drive # for Google Colab\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA6EpHuoqsRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037661aa-6e7d-4b6f-a7f2-1109bd267763"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import spacy\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data \n",
        "import torchtext\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "# Enables GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7_Cp7XS3rhp"
      },
      "source": [
        "## **1. Dataset Preparation**\r\n",
        "The first column contains the sentiments and the last column contains the tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tefpNlqP411B",
        "outputId": "2acaba2e-0fc2-4c88-c3b4-eee54338a0d7"
      },
      "source": [
        "# Read in data into a dataframe\r\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/tweet-dataset.csv\", engine=\"python\", header=None)\r\n",
        "\r\n",
        "df.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ...                                                  5\n",
              "0  0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1  0  ...  is upset that he can't update his Facebook by ...\n",
              "2  0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3  0  ...    my whole body feels itchy and like its on fire \n",
              "4  0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9KM2n7P36C5",
        "outputId": "608134da-fdec-4b90-80d3-980b5a6daedb"
      },
      "source": [
        "# Count the number of tweets per sentiment\r\n",
        "df[0].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7c5oo2q38HT",
        "outputId": "a7275b88-abba-42f0-b8ec-e0551452fae7"
      },
      "source": [
        "# Model the sentiments from polarity to binary (0 - negative, 1 - positive)\r\n",
        "df[0]=df[0].replace(to_replace=4,value=1)\r\n",
        "df[0].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    800000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1icG-Aiu39ix"
      },
      "source": [
        "# Subset as a smaller dataset from training\r\n",
        "df.sample(100000).to_csv(\"sentiment140-small.csv\", header=None, index=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23cJjM_d3_9N"
      },
      "source": [
        "## **2. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHmESNo45Xt",
        "outputId": "12ad366a-d3c9-45ca-c9d5-f0013fedcf9d"
      },
      "source": [
        "# Declare fields for tweets and labels\n",
        "TEXT = data.Field(tokenize='spacy', lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "# Map data to fields\n",
        "fields = [('label', LABEL), ('id',None),('date',None),('query',None),\n",
        "      ('name',None), ('text', TEXT),('category',None)]\n",
        "\n",
        "# Apply field definition to create torch dataset\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "        path=\"sentiment140-small.csv\",\n",
        "        format=\"CSV\",\n",
        "        fields=fields,\n",
        "        skip_header=False)\n",
        "\n",
        "# Split data into train, test, validation sets\n",
        "(train_data, test_data, valid_data) = dataset.split(split_ratio=[0.8,0.1,0.1])\n",
        "\n",
        "print(\"Number of train data: {}\".format(len(train_data)))\n",
        "print(\"Number of test data: {}\".format(len(test_data)))\n",
        "print(\"Number of validation data: {}\".format(len(valid_data)))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train data: 80000\n",
            "Number of test data: 10000\n",
            "Number of validation data: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SLzcTru48ls",
        "outputId": "c0838423-dc34-47eb-99b1-957f79cbd8b3"
      },
      "source": [
        "# An example from the training set\r\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': '1', 'text': ['ca', \"n't\", 'believe', 'ruben', 'likes', 'me', 'to', ',', 'but', 'it', 'is', 'true', '.', 'anyway', ',', 'i', \"'m\", 'have', 'to', 'make', 'my', 'homework', 'now', '.', 'ciao', 'you', 'guys', ' ', '@drakebell', 'write', 'write', '!', ':-d', ':-d']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjkMs-4w4_sH"
      },
      "source": [
        "### **Build Vocabulary**\r\n",
        "Build the vocabulary for the training set using pre-trained GloVe embeddings. GloVe embeddings were trained on 6 billion tokens and the embeddings are 100-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPL_jR0g4Cxf",
        "outputId": "259297e7-869a-4293-b424-f3a228172929"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\r\n",
        "\r\n",
        "# unk_init initializes words in the vocab using the Gaussian distribution\r\n",
        "TEXT.build_vocab(train_data, \r\n",
        "                 max_size = MAX_VOCAB_SIZE,\r\n",
        "                 vectors = \"glove.6B.100d\",\r\n",
        "                 unk_init = torch.Tensor.normal_)\r\n",
        "\r\n",
        "# build vocab for training set - convert words into integers\r\n",
        "LABEL.build_vocab(train_data)\r\n",
        "\r\n",
        "# Most frequent tokens\r\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 50045),\n",
              " ('!', 45331),\n",
              " ('.', 40455),\n",
              " (' ', 29285),\n",
              " ('to', 28320),\n",
              " ('the', 26188),\n",
              " (',', 24256),\n",
              " ('a', 19024),\n",
              " ('my', 15915),\n",
              " ('and', 15231)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhZ2YALE4Gvh"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "# sort_within_batch sorts all the tensors within a batch by their lengths\r\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "    batch_size = BATCH_SIZE, \r\n",
        "    device = device,\r\n",
        "    sort=False)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amH75Mpq4H-E"
      },
      "source": [
        "## **3. Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLbk7Tmf5N0Q"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \r\n",
        "                 dropout, pad_idx):\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "                \r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\r\n",
        "        \r\n",
        "        self.convs = nn.ModuleList([\r\n",
        "                                    nn.Conv2d(in_channels = 1, \r\n",
        "                                              out_channels = n_filters, \r\n",
        "                                              kernel_size = (fs, embedding_dim)) \r\n",
        "                                    for fs in filter_sizes\r\n",
        "                                    ])\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, text):\r\n",
        "                \r\n",
        "        #text = [batch size, sent len]\r\n",
        "        \r\n",
        "        embedded = self.embedding(text)\r\n",
        "                \r\n",
        "        #embedded = [batch size, sent len, emb dim]\r\n",
        "        \r\n",
        "        embedded = embedded.unsqueeze(1)\r\n",
        "        \r\n",
        "        #embedded = [batch size, 1, sent len, emb dim]\r\n",
        "        \r\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\r\n",
        "            \r\n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\r\n",
        "                \r\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\r\n",
        "        \r\n",
        "        #pooled_n = [batch size, n_filters]\r\n",
        "        \r\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\r\n",
        "\r\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\r\n",
        "            \r\n",
        "        return self.fc(cat)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Us3Q-HSi_BS"
      },
      "source": [
        "### **Create Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Go5cL75TWO"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "N_FILTERS = 100\r\n",
        "FILTER_SIZES = [3,4,5]\r\n",
        "OUTPUT_DIM = 1\r\n",
        "DROPOUT = 0.5\r\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "\r\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU0ZCiyQ5foy",
        "outputId": "78dcb61d-194b-4f98-ed41-0dff6f72e309"
      },
      "source": [
        "# Sample from the training set\r\n",
        "print(vars(train_iterator.dataset[0]))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': '1', 'text': ['ca', \"n't\", 'believe', 'ruben', 'likes', 'me', 'to', ',', 'but', 'it', 'is', 'true', '.', 'anyway', ',', 'i', \"'m\", 'have', 'to', 'make', 'my', 'homework', 'now', '.', 'ciao', 'you', 'guys', ' ', '@drakebell', 'write', 'write', '!', ':-d', ':-d']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JKN28_ah_jV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe21b53f-0a80-451c-f258-a53ee6191656"
      },
      "source": [
        "# Copy the pre-trained word embeddings into the embedding layer\r\n",
        "pretrained_embeddings = TEXT.vocab.vectors\r\n",
        "\r\n",
        "# [vocab size, embedding dim]\r\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq5K3bT35kWR",
        "outputId": "e18e6c32-33b1-43c8-95c9-aa901fc0d753"
      },
      "source": [
        "# Replace the initial weights of the embedding layer with the pre-trained embeddings\r\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3755,  0.0550, -0.1225,  ..., -0.9230, -0.8510, -0.9215],\n",
              "        [-0.7454, -0.8616, -0.6293,  ...,  0.6587,  0.1071, -0.7181],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [ 1.0402,  0.6146, -0.2181,  ...,  1.9460, -1.5685, -0.2946],\n",
              "        [-0.1222, -0.7869,  0.2676,  ...,  1.6120,  0.1865, -0.8650],\n",
              "        [ 0.2206, -0.0253, -0.0070,  ...,  0.4942,  0.0057,  0.1924]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouv1tRw5ott",
        "outputId": "aafb62cc-0741-4300-c02a-245395898725"
      },
      "source": [
        "# Initialize <unk> and <pad> both to all zeros - irrelevant for sentiment analysis\r\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\r\n",
        "\r\n",
        "# Setting row in the embedding weights matrix to zero using the token index\r\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\r\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\r\n",
        "\r\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
            "        ...,\n",
            "        [ 1.0402,  0.6146, -0.2181,  ...,  1.9460, -1.5685, -0.2946],\n",
            "        [-0.1222, -0.7869,  0.2676,  ...,  1.6120,  0.1865, -0.8650],\n",
            "        [ 0.2206, -0.0253, -0.0070,  ...,  0.4942,  0.0057,  0.1924]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk0yP1Xq5s7L"
      },
      "source": [
        "## **4. Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nArD8Ny5sBB"
      },
      "source": [
        "# Adam optimizer used to update the weights\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-3)\r\n",
        "\r\n",
        "# binary cross entropy\r\n",
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "# Use GPU\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZjHhKp268M2"
      },
      "source": [
        "def binary_accuracy(preds, y):\r\n",
        "    \"\"\"\r\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #round predictions to the closest integer\r\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\r\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyRlrOPSN7wB"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        predictions = model(batch.text).squeeze(1)\r\n",
        "        \r\n",
        "        loss = criterion(predictions, batch.label)\r\n",
        "        \r\n",
        "        acc = binary_accuracy(predictions, batch.label)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06z2unYo6_8k"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "\r\n",
        "            predictions = model(batch.text).squeeze(1)\r\n",
        "            \r\n",
        "            loss = criterion(predictions, batch.label)\r\n",
        "            \r\n",
        "            acc = binary_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b_BZ7fd7k7D"
      },
      "source": [
        "### **CNN Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIwdGJ1Q7CoM",
        "outputId": "18d0fda6-199c-4161-b57c-e455bf346f73"
      },
      "source": [
        "N_EPOCHS = 5\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "\r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'model-small.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 55s\n",
            "\tTrain Loss: 0.504 | Train Acc: 75.00%\n",
            "\t Val. Loss: 0.441 |  Val. Acc: 79.51%\n",
            "Epoch: 02 | Epoch Time: 1m 56s\n",
            "\tTrain Loss: 0.413 | Train Acc: 81.52%\n",
            "\t Val. Loss: 0.435 |  Val. Acc: 80.43%\n",
            "Epoch: 03 | Epoch Time: 1m 55s\n",
            "\tTrain Loss: 0.359 | Train Acc: 84.44%\n",
            "\t Val. Loss: 0.440 |  Val. Acc: 80.36%\n",
            "Epoch: 04 | Epoch Time: 1m 55s\n",
            "\tTrain Loss: 0.308 | Train Acc: 86.95%\n",
            "\t Val. Loss: 0.475 |  Val. Acc: 79.89%\n",
            "Epoch: 05 | Epoch Time: 1m 55s\n",
            "\tTrain Loss: 0.261 | Train Acc: 89.27%\n",
            "\t Val. Loss: 0.550 |  Val. Acc: 78.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WvzZRtt7tcf"
      },
      "source": [
        "## **5. Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX2r5KzE70gh",
        "outputId": "8ac63d57-dc08-4616-836c-13cca3167463"
      },
      "source": [
        "# Load the model with the best validation loss\r\n",
        "model.load_state_dict(torch.load('model-small.pt'))\r\n",
        "\r\n",
        "# Evaluate test loss and accuracy\r\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(\"Test Loss: {} | Test Acc: {}%\".format(round(test_loss, 2), round(test_acc*100, 2)))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.45 | Test Acc: 79.47%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}